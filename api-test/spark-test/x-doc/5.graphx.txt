1.图计算 对飙模型
    spark-core > RDD （Resilient Distribute Dataset）
    spark-sql > Dataframe Dataset
    spark-streaming > DStream (District Stream)
    spark-graphx > RDPG （Resilient Distribute Property Graph 弹性分布式属性图）

2.关键抽象
    顶点 RDD[(VertexId,VD)] o :每个顶点有一个Long 类型的 vertexID 和 属性VD
        VertexRDD[VD] 是RDD[(vertexId,VD)] 顶点的优化飙升

    边：RDD[Edge[ED]]  - ： 每条边都提供了一个源顶点 ID 和 目标顶点ID 以及该边的属性，Edge 就是一个边对象，ED 为边的属性类型
        EdgeRDD[ED]

    三元组 RDD[EdgeTriplet[VD,ED]] o-o : 每个三元组具有一个边属性 + 一个目标顶点 + 一个源顶点

    图：Graph[VD:ClassTag,ED:ClassTag] o-o-o ：VE 为顶点类型，ED 为边类型。

3.创建图
    // 泛型函数
      def doPrint[VD,ED](graph:Graph[VD,ED]):Unit={
        println("--------------------------")
        // 遍历三元组RDD
        graph.triplets.foreach{ t=>
          val srcId = t.srcId
          val srcAttr = t.srcAttr
          val dstId = t.dstId
          val dstAttr = t.dstAttr
          val edgeAttr = t.attr
          println(s"$srcId [$srcAttr] -> $edgeAttr -> $dstId [$dstAttr]")
        }
      }


    def main(args: Array[String]): Unit = {
        val conf = new SparkConf().set("spark.streaming,stopGracefullyOnShutdown","true").setMaster("local[4]").setAppName(getClass.getSimpleName)
        val sc = new SparkContext(conf)

        try{
            // 定义点的RDD VertexId 为long类型，描述点ID,(String,String) 代表VD 为点的属性，在此案例中第一个为姓名，第二个为职业
            val vertexRDD:RDD[(VertexId,(String,String))] = sc.makeRDD(Array((3L,("rxin","stu")),(5L,("franklin","prof")),(7L,("jgonzal","pst.doc")),(2L,("istoica","prof"))))

        // 定义边的RDD Edge[srcId,dstId,VertexId]
        val edgeRDD:RDD[Edge[String]] = sc.makeRDD(Array(Edge(5l,3l,"Advisor"),Edge(3l,7l,"Collab"),Edge(5l,7l,"PI"),Edge(2l,5l,"Colleague")))

        // 方案1：基于 点RDD 和 边RDD 创建 图
        val graph = Graph(vertexRDD,edgeRDD)
        doPrint(graph)
          /*
            2 [(istoica,prof)] -> Colleague -> 5 [(franklin,prof)]
            5 [(franklin,prof)] -> PI -> 7 [(jgonzal,pst.doc)]
            5 [(franklin,prof)] -> Advisor -> 3 [(rxin,stu)]
            3 [(rxin,stu)] -> Collab -> 7 [(jgonzal,pst.doc)]
           */

          // 方案2: 基于边构建图
          val graph2 = Graph.fromEdges(edgeRDD,"mygraph")
          doPrint(graph2)
          /*
            2 [mygraph] -> Colleague -> 5 [mygraph]
            3 [mygraph] -> Collab -> 7 [mygraph]
            5 [mygraph] -> PI -> 7 [mygraph]
            5 [mygraph] -> Advisor -> 3 [mygraph]
           */

          // 方案3：基于边元组创建图
          val edgeTripletRDD = edgeRDD.map(t=> (t.srcId,t.dstId))
          val graph3 = Graph.fromEdgeTuples(edgeTripletRDD,"mygraph2")
          doPrint(graph3)
          /*
            2 [mygraph2] -> 1 -> 5 [mygraph2]
            5 [mygraph2] -> 1 -> 3 [mygraph2]
            5 [mygraph2] -> 1 -> 7 [mygraph2]
            3 [mygraph2] -> 1 -> 7 [mygraph2]
           */

          // 过滤掉 职业为 prof 的顶点，构建子图
          val newVertexRDD = graph.vertices.filter(_._2._2!="prof")
          val subGraph = Graph(newVertexRDD,edgeRDD)
          doPrint(subGraph)
          /*
            2 [null] -> Colleague -> 5 [null]
            3 [(rxin,stu)] -> Collab -> 7 [(jgonzal,pst.doc)]
            5 [null] -> Advisor -> 3 [(rxin,stu)]
            5 [null] -> PI -> 7 [(jgonzal,pst.doc)]
           */

        }finally {
          if(!sc.isStopped){
            sc.stop()
          }
        }
    }

4.图计算基本操作
     val conf = new SparkConf().set("spark.streaming,stopGracefullyOnShutdown", "true").setMaster("local[4]").setAppName(getClass.getSimpleName)
        val sc = new SparkContext(conf)

        try {
          // 声明边RDD
          val edgeRDD = sc.makeRDD(Array(
            Edge(2l, 1l, 7),
            Edge(2l, 4l, 2),
            Edge(3l, 2l, 4),
            Edge(3l, 6l, 3),
            Edge(4l, 1l, 1),
            Edge(5l, 2l, 2),
            Edge(5l, 3l, 8),
            Edge(5l, 6l, 3)
          ))

          // 声明 顶点
          val vertexRDD = sc.makeRDD(Array(
            (1l, ("Alice", 28)),
            (2l, ("Bob", 27)),
            (3l, ("Charlie", 65)),
            (4l, ("David", 42)),
            (5l, ("Ed", 55)),
            (6l, ("Fran", 50))
          ))

          val graph = Graph(vertexRDD, edgeRDD)
          doPrint(graph)

          // 基本信息接口
          // 边个数
          val numEdges = graph.numEdges
          // 顶点个数
          val numVertices = graph.numVertices
          // 入度
          val inDegrees = graph.inDegrees
          // 出度
          val outDegrees = graph.outDegrees
          //inDegrees + outDegrees
          val degress = graph.degrees
          // 全部边
          val edges = graph.edges
          // 全部顶点
          val vertices = graph.vertices
          // 全部三元组
          val triplets = graph.triplets

          // 转换操作 对全部顶点进行遍历转换
          val transformGraph1 = graph.mapVertices{
            case (vid,(name,age)) => s"${vid}:${name}_${age}"
          }
          doPrint(transformGraph1)

          // 对全部边进行遍历转换
          val transformGraph2 = graph.mapEdges{
            e => e.srcId+" -> "+e.attr+" -> "+e.dstId
          }
          doPrint(transformGraph2)

          // 对全部三元组进行遍历
          val transformGraph3 =graph.mapTriplets{ trip =>
            trip.srcId +" -> "+trip.attr +" -> "+trip.dstId
          }
          doPrint(transformGraph3)

          // 边方向翻转
          val reversedGraph = graph.reverse
          doPrint(reversedGraph)

    //      def subgraph(
          // epred : scala.Function1[org.apache.spark.graphx.EdgeTriplet[VD, ED], scala.Boolean] = { /* compiled code */ }, Edge(2l, 1l, 7)
          // vpred : scala.Function2[org.apache.spark.graphx.VertexId, VD, scala.Boolean] = { /* compiled code */ } (1l, ("Alice", 28))
          // ) : org.apache.spark.graphx.Graph[VD, ED]
          val sub = graph.subgraph(epred=(et) => et.attr > 5,vpred = (vertex,attr) => attr._2 > 50)
          doPrint(sub)

          // 声明边RDD
          val edgeRDD2 = sc.makeRDD(Array(
            Edge(1l, 2l, 7),
            Edge(2l, 4l, 2),
            Edge(2l, 3l, 4),
            Edge(3l, 6l, 3),
            Edge(4l, 1l, 1),
            Edge(5l, 2l, 2),
            Edge(5l, 3l, 8),
            Edge(5l, 6l, 12)
          ))

          // 声明 顶点
          val vertexRDD2 = sc.makeRDD(Array(
            (1l, ("Alice", 28)),
            (2l, ("Bob", 27)),
            (3l, ("Charlie", 65)),
            (4l, ("David", 42)),
            (5l, ("Ed", 55)),
            (6l, ("Fran", 50))
          ))

          // 取两个图的相较的边，构建的新图进行打印输出，如果边属性不一致，已前者的属性为准
          val graph2 = Graph(vertexRDD2,edgeRDD2)
          val intersectGraph = graph.mask(graph2)
          doPrint(intersectGraph)


          val edgeRDD3 = sc.makeRDD(Array(
            Edge(1l, 2l, 7),
            Edge(2l, 4l, 5),
            Edge(2l, 3l, 4),
            Edge(3l, 6l, 3),
            Edge(4l, 1l, 1),
            Edge(5l, 2l, 2),
            Edge(5l, 3l, 8),
            Edge(5l, 6l, 12),
            Edge(2l, 4l, 5)
          ))

          // 声明 顶点
          val vertexRDD3 = sc.makeRDD(Array(
            (1l, ("Alice", 28)),
            (2l, ("Bob", 27)),
            (3l, ("Charlie", 65)),
            (4l, ("David", 42)),
            (5l, ("Ed", 55)),
            (6l, ("Fran", 50))
          ))

          val graph3 = Graph(vertexRDD3,edgeRDD3.repartition(1))
          graph3.edges.mapPartitionsWithIndex((index,iter)=> Iterator(index+":"+iter.mkString("|"))).foreach(println)

          // 将图中 通分区内，相同起止点 边 进行收集聚合操作
          val edgeGroup = graph3.groupEdges(_+_)
          doPrint(edgeGroup)

          // 顶点关联操作
          // 将外部顶点的rdd 与 当前图 相同顶点的 rdd 进行join (内连接)
          val newVertex = sc.makeRDD(Array((1l, 28)))
          val newGraph = graph3.joinVertices(newVertex)((vid,attr,newAttr) =>(attr._1+newAttr,attr._2))
          doPrint(newGraph)

          // 将外部顶点的rdd 与 当前图 相同顶点的 rdd 进行join (外连接)，未匹配上的可以赋默认值
          val newGraph2 = graph3.outerJoinVertices(newVertex)((vid,attr,newAttr) =>(attr._1+newAttr.getOrElse(22),attr._2))
          doPrint(newGraph2)

          // 收集顶点周围邻居，方向，入度
          graph.collectNeighbors(EdgeDirection.In).collect().foreach(t=> println(t._1 + "\t"+t._2.mkString("|")))

          // 聚合指向顶点的边的其他顶点，由边想当前顶点发消息，统计最大的源顶点，然后输出
          val aggGraph = graph.aggregateMessages[(String,Int)](
            ctx=> ctx.sendToDst(ctx.srcAttr), // 各边将想目标顶点，发送源顶点的消息
            (x,y) => if (x._2 >=y._2) x else y // 比较源顶点，取最大值
          )
          aggGraph.foreach(println)


        } finally {
          if (sc.isStopped) {
            sc.stop()
          }

5.Pregel 最短路径计算模型
 def pregel[A](initialMsg : A,  // 初始化  no1
  maxIterations : scala.Int , // 最大迭代深度 no2
  activeDirection : org.apache.spark.graphx.EdgeDirection) // 跌打计算方向 (1 入) no3

  (vprog : scala.Function3[org.apache.spark.graphx.VertexId, VD, A, VD],  // 汇总收到的消息，并取最小值替换当前节点属性 (最后一步汇总比较)  no4
  sendMsg : scala.Function1[org.apache.spark.graphx.EdgeTriplet[VD, ED],  // 默认源节点携带三元组属性发送给目标节点  no5
  scala.Iterator[scala.Tuple2[org.apache.spark.graphx.VertexId, A]]], // src 往 dst 发送消息 当srcAttr+edgeAttr < dstAttr，dst 就接受，否则拒绝 no6
  mergeMsg : scala.Function2[A, A, A])(implicit evidence$6 : scala.reflect.ClassTag[A]) : org.apache.spark.graphx.Graph[VD, ED] // 不同源节点先后往 目标节点发送消息，两两比较，取最新值 no7
  )

  val conf = new SparkConf().set("spark.streaming,stopGracefullyOnShutdown","true").setMaster("local[4]").setAppName(getClass.getSimpleName)
  val sc = new SparkContext(conf)

  try {

    // 声明边RDD
    val edgeRDD = sc.makeRDD(Array(
      Edge(2l, 1l, 7),
      Edge(2l, 4l, 2),
      Edge(3l, 2l, 4),
      Edge(3l, 6l, 3),
      Edge(4l, 1l, 1),
      Edge(2l, 5l, 2),
      Edge(5l, 3l, 8),
      Edge(5l, 6l, 3)
    ))

    // 声明 顶点
    val vertexRDD = sc.makeRDD(Array(
      (1l, ("Alice", 28)),
      (2l, ("Bob", 27)),
      (3l, ("Charlie", 65)),
      (4l, ("David", 42)),
      (5l, ("Ed", 55)),
      (6l, ("Fran", 50))
    ))

    val graph = Graph(vertexRDD, edgeRDD)

    // 研究 5 到其他点的最短距离
    val sourceId: VertexId = 5l
    //  初始化： 除目标点外，其余顶点全部初始化为整无穷大
    val initedGraph = graph.mapVertices((id, _) => if (id == sourceId) 0.0 else Double.PositiveInfinity)
    val resultGraph = initedGraph.pregel(Double.PositiveInfinity )(// 终止条件 vprog，累计到最大值才终止
       (id, dist, newDist) => {
        println(s"\n\ndestID:$id [oldVal:$dist,newVal:$newDist]");
        math.min(dist, newDist)
      }, // dst 节点最终将自身值 与 ，筛选出的最小的 srcAttr+attr 值进行比较，取较小值，然后更新给执行
      triplet => { // 默认 src 节点将 三元组信息发送给 dst 节点，复合比较条件，就表名发送 和 接受 成功，否则失败，，当某节点发送 和 接收消息全部失败，则进入钝化态，不参与下次迭代，否则继续擦怒下次迭代
        if (triplet.srcAttr + triplet.attr < triplet.dstAttr) {
          triplet.dstId
          println(s"${triplet.srcId} -> ${triplet.dstId} 发送成功 triplet.srcAttr + triplet.attr: ${triplet.srcAttr + triplet.attr} < triplet.dstAttr: ${triplet.dstAttr}")
          Iterator((triplet.dstId, triplet.srcAttr + triplet.attr))
        } else {
          Iterator.empty
        }
      },
      (a, b) => {
        println(s"src节点们，发送给dst的消息两两比较 (a:${a},)");
        math.min(a, b)
      } // 所有 src 发送过来的消息，先进行汇总，然后交给 (id,dist,newDist) => {math.min(dist,newDist)}, 进行最终合并更新
    )

    resultGraph.vertices.foreach(x=>println(s"vid:${x._1} [${x._2}]"))

  }finally {
    if(sc.isStopped){
      sc.stop()
    }
  }
