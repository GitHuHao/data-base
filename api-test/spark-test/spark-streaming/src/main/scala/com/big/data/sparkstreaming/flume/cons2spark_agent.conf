##  功能: flume 接受 4040 端口发送的数据，然后交给 spark 消费
# 启动 agent: nohup bin/flume-ng agent  --conf conf/ --name cons2spark_agent --conf-file agent/cons2spark_agent.conf -Dflume.root.logger=DEBUG,console 2>&1 &
# 输入: netcat localhost 4040

# 声明组件
cons2spark_agent.sources = mycat
cons2spark_agent.sinks = logger spark
cons2spark_agent.channels = memory1 memory2

# 定义 source 并拷贝副本
cons2spark_agent.sources.mycat.type = netcat
cons2spark_agent.sources.mycat.bind = localhost
cons2spark_agent.sources.mycat.port = 44444
cons2spark_agent.sources.mycat.selector.type = replicating


# 定义 sparksink 输出
cons2spark_agent.sinks.spark.type = org.apache.spark.streaming.flume.sink.SparkSink
cons2spark_agent.sinks.spark.hostname = localhost
cons2spark_agent.sinks.spark.port = 9999
cons2spark_agent.sinks.spark.channel = memory1

# 定义 loggesink 输出
cons2spark_agent.sinks.logger.type=logger

# 定义两个 channel ## 基于内存,构建数据通道
cons2spark_agent.channels.memory1.type = memory
cons2spark_agent.channels.memory1.capacity = 1000
cons2spark_agent.channels.memory1.transactionCapacity = 100

cons2spark_agent.channels.memory2.type = memory
## 数据通道最大事件个数负载(默认1000)
cons2spark_agent.channels.memory2.capacity = 1000
## 数据单次会话最大事件负载(默认100)
cons2spark_agent.channels.memory2.transactionCapacity = 100

# 组装
cons2spark_agent.sources.mycat.channels = memory1 memory2
cons2spark_agent.sinks.logger.channel=memory1
cons2spark_agent.sinks.spark.channel=memory2


