## 功能: flume 使用shell命令监控本地日志文件,实时上传数据到hdfs
# nohup java -jar call-mocker-1.0-SNAPSHOT-jar-with-dependencies.jar 2>&1  &
# nohup flume-ng agent --conf $FLUME_HOME/conf/ --name tail2hdfs_agent --conf-file $FLUME_HOME/agent/tail2hdfs_agent.conf 2>&1 &
# step1: 声明3大组件

## 数据输入源sources
tail2hdfs_agent.sources=r2
## 数据输出源
tail2hdfs_agent.sinks=k2
## 数据传输通道
tail2hdfs_agent.channels=c2


# step2: 定义source

## source类似为exec 从可执行命令,获取数据
tail2hdfs_agent.sources.r2.type=exec
## 执行脚本内容'tail -F' 监控文件,异常崩溃,会尝试重连
tail2hdfs_agent.sources.r2.command=tail -F /Users/huhao/software/virtual_space/running_jars/call-mocker/logs/call.log
## shell命令
tail2hdfs_agent.sources.r2.shell=/bin/bash -c


# step3: 定义sink

## sink类型hdfs(数据输入到hdfs上)
tail2hdfs_agent.sinks.k2.type=hdfs
## 上传hdfs路径
tail2hdfs_agent.sinks.k2.hdfs.path=hdfs://localhost:9000/tmp/flume/%Y%m%d%H
## 文件前缀
tail2hdfs_agent.sinks.k2.hdfs.filePrefix=hive-
## 上传数据启用滚动策略
tail2hdfs_agent.sinks.k2.hdfs.round=true
## 文件夹滚动时间间隔1h
tail2hdfs_agent.sinks.k2.hdfs.roundValue=1
tail2hdfs_agent.sinks.k2.hdfs.roundUnit=hour
## 启用本地时间戳
tail2hdfs_agent.sinks.k2.hdfs.useLocalTimeStamp=true
## channel中累计批处理event事件个数(1000个/批)
tail2hdfs_agent.sinks.k2.hdfs.batchSize=1000
## 上传数据类型(支持压缩)
tail2hdfs_agent.sinks.k2.hdfs.fileType=DataStream
## 文件滚动策略(10min/次 或 127MB/次略小于128Mb)
tail2hdfs_agent.sinks.k2.hdfs.rollInterval=600
tail2hdfs_agent.sinks.k2.hdfs.rollSize=134217700
## 文件滚动与Event事件格式无关
tail2hdfs_agent.sinks.k2.hdfs.rollCount=0
## 最小冗余副本数(hdfs默认为3)
tail2hdfs_agent.sinks.k2.hdfs.minBlockReplicas=1


# step4: 定义channel

## 数据通道(队列)基于内存工作
tail2hdfs_agent.channels.c2.type=memory
## 通道总负载 1000 Event
tail2hdfs_agent.channels.c2.capacity=1000
## 通道会话负载 100 Event
tail2hdfs_agent.channels.c2.transactionCapacity=100


# step5: 组装
## 每个source可以给多个channel提供数据
tail2hdfs_agent.sources.r2.channels=c2
## 每个sink只能接收一个channel的数据
tail2hdfs_agent.sinks.k2.channel=c2