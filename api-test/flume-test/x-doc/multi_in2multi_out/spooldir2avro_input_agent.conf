## 功能: flume 监控文件目录,将新投入其中的文件实时上传到hdfs

#  nohup bin/flume-ng agent  --conf conf/ --name spooldir2avro_input_agent --conf-file agent/multi_in2multi_out/spooldir2avro_input_agent.conf 2>&1 &

# step1: 声明3大组件
spooldir2avro_input_agent.sources = r1
spooldir2avro_input_agent.sinks = k1
spooldir2avro_input_agent.channels = c1


# step2: 定义source(数据输入源)

## source 类型(监控文件目录)
spooldir2avro_input_agent.sources.r1.type = spooldir
## source监控对象
spooldir2avro_input_agent.sources.r1.spoolDir = /Users/huhao/software/flume-1.8.0/upload
## 上传完成后缀标记
spooldir2avro_input_agent.sources.r1.fileSuffix = .COMPLETED
## 是否对文件头部进行标记
spooldir2avro_input_agent.sources.r1.fileHeader = true
## 忽略所有以.tmp结尾的文件,不进行上传
spooldir2avro_input_agent.sources.r1.ignorePattern = ([^ ]*\.tmp)


# step3: 定义k1,flume4将监控的本地文件夹文件,实时传送给flume3

spooldir2avro_input_agent.sinks.k1.type = avro
spooldir2avro_input_agent.sinks.k1.hostname = localhost
spooldir2avro_input_agent.sinks.k1.port = 4142


# step4: 定义channel组件(数据通道)

## 基于内存建立数据通道(队列)
spooldir2avro_input_agent.channels.c1.type = memory
## 通道Event队列,最大容量为1000个
spooldir2avro_input_agent.channels.c1.capacity = 1000
## 通道每个事务队列容量为100个Event
spooldir2avro_input_agent.channels.c1.transactionCapacity = 100


# step5: 组装
spooldir2avro_input_agent.sources.r1.channels = c1
spooldir2avro_input_agent.sinks.k1.channel = c1
 