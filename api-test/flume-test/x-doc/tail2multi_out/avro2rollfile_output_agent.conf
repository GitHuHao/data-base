# 功能: flume3 (hadoop104)接收flume1(hadoop102)输入数据.然后在本地指定目录按默认回滚策略保存

#  nohup bin/flume-ng agent  --conf conf/ --name avro2rollfile_output_agent --conf-file agent/tail2multi_out/avro2rollfile_output_agent.conf 2>&1 &

# step1: 声明三大组件
avro2rollfile_output_agent.sources = r1
avro2rollfile_output_agent.sinks = k1
avro2rollfile_output_agent.channels = c1


# step2: 定义r1 组件,从本机的4142端口获取flume1(hadoop102)推送过来的数据
avro2rollfile_output_agent.sources.r1.type = avro
avro2rollfile_output_agent.sources.r1.bind = localhost
avro2rollfile_output_agent.sources.r1.port = 4142


# step3: 定义k1 组件,基于文件滚动机制,保存在本地文件系统
avro2rollfile_output_agent.sinks.k1.type = file_roll
avro2rollfile_output_agent.sinks.k1.sink.directory = /Users/huhao/software/flume-1.8.0/tmp


# step4: 定义c1组件(基于内存构建事件队列) 通道负载最大并发量1000个Event事件,100个事务
avro2rollfile_output_agent.channels.c1.type = memory
avro2rollfile_output_agent.channels.c1.capacity = 1000
avro2rollfile_output_agent.channels.c1.transactionCapacity = 100


# step5: 组装
avro2rollfile_output_agent.sources.r1.channels = c1
avro2rollfile_output_agent.sinks.k1.channel = c1