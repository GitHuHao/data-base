# 功能: flume2 (hadoop103) 到指定4141端口接收flume1传入的数据,然后上传到hdfs,解决flume1负载过重问题

# nohup bin/flume-ng agent  --conf conf/ --name avro2hdfs_output_agent --conf-file agent/tail2multi_out/avro2hdfs_output_agent.conf 2>&1 &

# step1: 声明三大组件(r1->c1->k1)
avro2hdfs_output_agent.sources = r1
avro2hdfs_output_agent.sinks = k1
avro2hdfs_output_agent.channels = c1


# step2: 定义r1组件,监听本机的hadoop103节点4141端口数据信息
avro2hdfs_output_agent.sources.r1.type = avro
avro2hdfs_output_agent.sources.r1.bind = localhost
avro2hdfs_output_agent.sources.r1.port = 4141

# step3: 定义k1组件,上传数据到hdfs
avro2hdfs_output_agent.sinks.k1.type = hdfs
avro2hdfs_output_agent.sinks.k1.hdfs.path = hdfs://localhost:9000/tmp/flume/avro/%Y%m%d%H
#上传文件的前缀
avro2hdfs_output_agent.sinks.k1.hdfs.filePrefix = flume2-
#是否按照时间滚动文件夹
avro2hdfs_output_agent.sinks.k1.hdfs.round = true
#多少时间单位创建一个新的文件夹
avro2hdfs_output_agent.sinks.k1.hdfs.roundValue = 1
#重新定义时间单位
avro2hdfs_output_agent.sinks.k1.hdfs.roundUnit = hour
#是否使用本地时间戳
avro2hdfs_output_agent.sinks.k1.hdfs.useLocalTimeStamp = true
#积攒多少个Event才flush到HDFS一次
avro2hdfs_output_agent.sinks.k1.hdfs.batchSize = 100
#设置文件类型，可支持压缩
avro2hdfs_output_agent.sinks.k1.hdfs.fileType = DataStream
#多久生成一个新的文件
avro2hdfs_output_agent.sinks.k1.hdfs.rollInterval = 600
#设置每个文件的滚动大小大概是128M(略小于)
avro2hdfs_output_agent.sinks.k1.hdfs.rollSize = 134217700
#文件的滚动与Event数量无关
avro2hdfs_output_agent.sinks.k1.hdfs.rollCount = 0
#最小冗余数
avro2hdfs_output_agent.sinks.k1.hdfs.minBlockReplicas = 1


# step4: 定义c1组件(基于内存构建事件队列) 通道负载最大并发量1000个Event事件,100个事务
avro2hdfs_output_agent.channels.c1.type = memory
avro2hdfs_output_agent.channels.c1.capacity = 1000
avro2hdfs_output_agent.channels.c1.transactionCapacity = 100


# step5: 组装
avro2hdfs_output_agent.sources.r1.channels = c1
avro2hdfs_output_agent.sinks.k1.channel = c1